{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discriminator\n",
    "\n",
    "**paper manuscript about discriminator:**\n",
    "The discriminator consisted of five convolutional layers followed by an average pooling layer and two fully connected layers. The output layer of the discriminator was a 2-way softmax and the network was trained to discriminate the reconstructed image from the original image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class japan_discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - init_features : int\n",
    "    Inputs:\n",
    "        - x : Tensor : (N, C, H, W)\n",
    "    Outputs:\n",
    "        - : Tensor : (N, 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, init_features = 32):\n",
    "        super(japan_discriminator, self).__init__()\n",
    "\n",
    "        self.disc_1 = nn.Sequential(\n",
    "            japan_discriminator._block_Conv2D(3, init_features, 7, 4),\n",
    "            japan_discriminator._block_Conv2D(init_features, 2*init_features, 5, 1),\n",
    "            japan_discriminator._block_Conv2D(2*init_features, 4*init_features, 3, 2),\n",
    "            japan_discriminator._block_Conv2D(4*init_features, 8*init_features, 3, 1),\n",
    "            japan_discriminator._block_Conv2D(8*init_features, 8*init_features, 3, 2),\n",
    "            nn.AvgPool2d(11,11)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.disc_2 = nn.Sequential(\n",
    "            japan_discriminator._block_FC(8*init_features, 8*init_features),\n",
    "            nn.ReLU(),\n",
    "            japan_discriminator._block_FC(8*init_features, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc_2(\n",
    "            self.disc_1(x).flatten(start_dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block_Conv2D(in_channels, out_channels, kernel_size, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _block_FC(in_features, out_features):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, out_features)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 2])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "N, C, H, W = 64, 3, 227, 227\n",
    "device = 'cuda'\n",
    "disc = japan_discriminator().to(device)\n",
    "\n",
    "x = torch.empty(N, C, H, W).normal_(0,1.0).to(device)\n",
    "\n",
    "disc(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "1081410"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters\n",
    "count_parameters(disc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generator\n",
    "\n",
    "**paper manuscript about generator:**\n",
    "The generator consisted of three fully connected layers followed by six upconvolution layers that generated the final reconstruction image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "class japan_generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - num_voxel : int\n",
    "        - noise_shape : tuple\n",
    "    Inputs:\n",
    "        - x : Tensor : (N, num_voxel)\n",
    "    Outputs:\n",
    "        - : Tensor : (N, 3, H, W)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_voxel, noise_shape = (64,2,2)):\n",
    "        super(japan_generator, self).__init__()\n",
    "\n",
    "        self.noise_shape = noise_shape\n",
    "\n",
    "        self.gen_1 = nn.Sequential(\n",
    "            japan_generator._block_FC(num_voxel, math.prod(noise_shape)),\n",
    "            japan_generator._block_FC(math.prod(noise_shape), math.prod(noise_shape)),\n",
    "            japan_generator._block_FC(math.prod(noise_shape), math.prod(noise_shape))\n",
    "        )\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.gen_2 = nn.Sequential(\n",
    "            japan_generator._block_UpConv2D(noise_shape[0], noise_shape[0], 4, 2),\n",
    "            japan_generator._block_UpConv2D(noise_shape[0], 2*noise_shape[0], 3, 1),\n",
    "            japan_generator._block_UpConv2D(2*noise_shape[0], noise_shape[0], 4, 2),\n",
    "            japan_generator._block_UpConv2D(noise_shape[0], noise_shape[0], 3, 1),\n",
    "            japan_generator._block_UpConv2D(noise_shape[0], int(noise_shape[0]/2), 4, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/2), int(noise_shape[0]/2), 3, 1),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/2), int(noise_shape[0]/4), 4, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/4), int(noise_shape[0]/8), 4, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/8), 3, 4, 2)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.gen_2 = nn.Sequential(\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/1), int(noise_shape[0]/1), 6, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/1), int(noise_shape[0]/2), 6, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/2), int(noise_shape[0]/2), 6, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/2), int(noise_shape[0]/4), 6, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/4), int(noise_shape[0]/8), 6, 2),\n",
    "            japan_generator._block_UpConv2D(int(noise_shape[0]/8), 3, 6, 2)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen_2(\n",
    "            self.gen_1(x).view((-1,)+self.noise_shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block_UpConv2D(in_channels, out_channels, kernel_size, stride, final_layer=False):\n",
    "        if final_layer == False:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding=1),\n",
    "                nn.LeakyReLU(negative_slope=0.3)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding=1)\n",
    "            )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block_FC(in_features, out_features):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.LeakyReLU(negative_slope=0.3)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 3, 254, 254])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "N, num_voxel = 64, 11760\n",
    "device = 'cpu'\n",
    "gen = japan_generator(num_voxel).to(device)\n",
    "\n",
    "x = torch.empty(N, num_voxel).normal_(0,1.0).to(device)\n",
    "\n",
    "gen(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "3424507"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of parameters\n",
    "count_parameters(gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}