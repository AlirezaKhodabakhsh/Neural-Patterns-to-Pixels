{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch library\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# torchvision library\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import savemat\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import math\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import networkx as nx\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.,  1.,  1., ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ...,  1., nan, nan],\n       ...,\n       [ 0.,  0.,  0., ..., nan, nan, nan],\n       [ 1.,  1.,  1., ..., nan, nan, nan],\n       [ 1.,  1.,  1., ..., nan, nan, nan]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"\\data\\\\fmri\\sub-01_perceptionNaturalImageTraining_original_VC.h5\"\n",
    "f = h5py.File(os.getcwd() + filename, 'r')\n",
    "np.array(f['metadata']['value'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(6000, 11730)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f['dataset']).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "interviews_df = pd.read_csv(os.getcwd() + '\\imagenet\\stimulus_perceptionNaturalImageTraining.tsv', sep='\\t')\n",
    "\n",
    "# every element is sting\n",
    "imagenet_names = interviews_df.to_numpy()[:,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "for i in imagenet_names:\n",
    "    a=i\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}